{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('datascience': conda)",
   "display_name": "Python 3.7.9 64-bit ('datascience': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f90bca0613efed7ecabf5471fffaa3c59b574bc50ff8d7750106372263da6181"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(221525, 40)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from pandas_profiling import ProfileReport\n",
    "df_orig = pd.read_csv('Collisions.csv')\n",
    "df_orig.shape"
   ]
  },
  {
   "source": [
    "Now let's have a closer look at what the data looks like. I will use pandas_profiling package to provide details and I will use it to ascertain which columns to drop (identifier columns) and which need some cleaning up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# profile = ProfileReport(df,title='Collisions initial profile')\n",
    "# profile.to_file('profile.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop: OBJECTID, INCKEY, COLDETKEY, REPORTNO, LOCATION, STATUS, INJURIES, SERIOUSINJURIES, FATALITIES, SDOTCOLNUM, SEGLANEKEY, CROSSWALKKEY\n",
    "# columns to keep separate: SEVERITYCODE, SEVERITYDESC, COLLISIONTYPE, SDOT_COLDESC, ST_COLDESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([&#39;X&#39;, &#39;Y&#39;, &#39;ADDRTYPE&#39;, &#39;INTKEY&#39;, &#39;EXCEPTRSNCODE&#39;, &#39;EXCEPTRSNDESC&#39;,\n       &#39;SEVERITYCODE&#39;, &#39;COLLISIONTYPE&#39;, &#39;PERSONCOUNT&#39;, &#39;PEDCOUNT&#39;,\n       &#39;PEDCYLCOUNT&#39;, &#39;VEHCOUNT&#39;, &#39;INCDATE&#39;, &#39;INCDTTM&#39;, &#39;JUNCTIONTYPE&#39;,\n       &#39;SDOT_COLCODE&#39;, &#39;SDOT_COLDESC&#39;, &#39;INATTENTIONIND&#39;, &#39;UNDERINFL&#39;,\n       &#39;WEATHER&#39;, &#39;ROADCOND&#39;, &#39;LIGHTCOND&#39;, &#39;PEDROWNOTGRNT&#39;, &#39;SPEEDING&#39;,\n       &#39;ST_COLCODE&#39;, &#39;HITPARKEDCAR&#39;],\n      dtype=&#39;object&#39;)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = df_orig.copy()\n",
    "df.drop(columns=['OBJECTID','INCKEY','COLDETKEY','REPORTNO','LOCATION','STATUS','INJURIES','SERIOUSINJURIES','FATALITIES','SDOTCOLNUM','SEGLANEKEY','CROSSWALKKEY','SEVERITYDESC','ST_COLDESC'],inplace=True)\n",
    "\n",
    "# clean ST_COLCODE\n",
    "def st_colcode(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['ST_COLCODE'] = df['ST_COLCODE'].apply(st_colcode)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     2013/03/14 00:00:00+00\n1     2006/01/15 00:00:00+00\n2     2019/09/09 00:00:00+00\n3     2019/12/19 00:00:00+00\n4     2013/03/27 00:00:00+00\n5     2005/07/07 00:00:00+00\n6     2020/07/31 00:00:00+00\n7     2013/04/01 00:00:00+00\n8     2006/04/11 00:00:00+00\n9     2013/04/03 00:00:00+00\n10    2013/03/30 00:00:00+00\n11    2013/03/31 00:00:00+00\n12    2006/06/13 00:00:00+00\n13    2019/12/23 00:00:00+00\n14    2007/04/17 00:00:00+00\n15    2004/09/17 00:00:00+00\n16    2019/12/20 00:00:00+00\n17    2013/03/27 00:00:00+00\n18    2020/05/03 00:00:00+00\n19    2019/12/22 00:00:00+00\nName: INCDATE, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['INCDATE'].head(20)"
   ]
  },
  {
   "source": [
    "#### Feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['INCDATE'],format=r'%Y/%m/%d %H:%M:%S+00')\n",
    "df['DATE']\n",
    "df['YEAR'] = df['DATE'].apply(lambda x: x.year)\n",
    "df['DAYOFYEAR'] = df['DATE'].apply(lambda x: x.dayofyear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetime(val:str):\n",
    "    if ' ' in val:\n",
    "        min_char = val.find(' ') + 1\n",
    "        new_time = time.strptime(val[min_char:],r'%I:%M:%S %p')\n",
    "        return new_time.tm_hour*60+new_time.tm_min*60\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['TIME'] = df['INCDTTM'].apply(parse_datetime)\n",
    "df['TIME'].replace(to_replace=np.nan, value=int(df['TIME'].mean()),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_time(val):\n",
    "    date = val['DATE']\n",
    "    hour = int(val['TIME']/3600)\n",
    "    minute = int((val['TIME']-3600*hour)/60)\n",
    "    return datetime.datetime.combine(date,datetime.time(hour,minute,0))\n",
    "\n",
    "df['DATETIME'] = df[['DATE','TIME']].apply(combine_date_time,axis=1)\n",
    "df['DATETIME'] = df['DATETIME'].apply(lambda x: x.timestamp())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['INCDATE','INCDTTM','DATE','YEAR','TIME','SDOT_COLDESC','EXCEPTRSNDESC','INTKEY','ST_COLCODE'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRTYPE'].replace({'Block':1,'Intersection':2,'Alley':3},inplace=True)\n",
    "df['EXCEPTRSNCODE'].replace({'NEI':1,'':0,' ':0},inplace=True)\n",
    "\n",
    "df['INATTENTIONIND'].replace({'Y':1,'':0,' ':0,'1':1,'0':0},inplace=True)\n",
    "df['INATTENTIONIND'].fillna(0,inplace=True)\n",
    "\n",
    "df['UNDERINFL'].replace({'Y':1,'N':0},inplace=True)\n",
    "\n",
    "df['WEATHER'].replace(\n",
    "    {\n",
    "        'Clear':0,\n",
    "        'Overcast':1,\n",
    "        'Partly Cloudy':1,\n",
    "        'Raining':2,\n",
    "        'Snowing':3,\n",
    "        'Fog/Smog/Smoke':4,\n",
    "        'Sleet/Hail/Freezing Rain':5,\n",
    "        'Blowing Sand/Dirt':6,\n",
    "        'Severe Crosswind':7,\n",
    "        'Blowing Snow':3,\n",
    "        'Unknown':np.nan,\n",
    "        '':np.nan\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df['ROADCOND'].replace(\n",
    "    {\n",
    "        'Dry':0,\n",
    "        'Wet':1,\n",
    "        'Ice':4,\n",
    "        'Snow/Slush':3,\n",
    "        'Standing Water':2,\n",
    "        'Sand/Mud/Dirt':5,\n",
    "        'Oil':6,\n",
    "        'Other':7,\n",
    "        'Unknown':np.nan,\n",
    "        '':np.nan\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df['LIGHTCOND'].replace(\n",
    "    {\n",
    "        'Daylight':0,\n",
    "        'Dusk':1,\n",
    "        'Dawn':2,\n",
    "        'Dark - Street Lights On':3,\n",
    "        'Dark - Street Lights Off':4,\n",
    "        'Dark - No Street Lights':5,\n",
    "        'Dark - Unknown Lighting':6,\n",
    "        'Other':7,\n",
    "        'Unknown':np.nan,\n",
    "        '':np.nan\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df['PEDROWNOTGRNT'].replace({'Y':1},inplace=True)\n",
    "df['PEDROWNOTGRNT'].fillna(0,inplace=True)\n",
    "\n",
    "df['SPEEDING'].replace({'Y':1},inplace=True)\n",
    "df['SPEEDING'].fillna(0,inplace=True)\n",
    "\n",
    "df['HITPARKEDCAR'].replace({'N':0,'Y':1},inplace=True)\n",
    "\n",
    "df['JUNCTIONTYPE'].replace(\n",
    "    {\n",
    "        'Unknown':0,\n",
    "        'Mid-Block (not related to intersection)':1,\n",
    "        'At Intersection (intersection related)':2,\n",
    "        'Mid-Block (but intersection related)':3,\n",
    "        'Driveway Junction':4,\n",
    "        'At Intersection (but not related to intersection)':5,\n",
    "        'Ramp Junction':6,\n",
    "        '':np.nan\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "df['JUNCTIONTYPE'].fillna(0,inplace=True)\n",
    "df.fillna(df.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Summarize dataset: 100%|██████████| 36/36 [00:44&lt;00:00,  1.25s/it, Completed]\nGenerate report structure: 100%|██████████| 1/1 [00:05&lt;00:00,  5.78s/it]\nRender HTML: 100%|██████████| 1/1 [00:03&lt;00:00,  3.68s/it]\nExport report to file: 100%|██████████| 1/1 [00:00&lt;00:00, 25.03it/s]\n"
    }
   ],
   "source": [
    "profile_clean = ProfileReport(df,title='Collisions data profile - cleaned',dark_mode=True)\n",
    "profile_clean.to_file('profile_clean.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0                          119492\n3                           50133\n1                            6082\n2                            2609\n5                            1579\n4                            1239\n7                             244\nDark - Unknown Lighting        23\nName: LIGHTCOND, dtype: int64"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}